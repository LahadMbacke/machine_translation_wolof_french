{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /home/lahad/.local/lib/python3.10/site-packages (from torchtext==0.6) (2.3.0)\n",
            "Requirement already satisfied: sentencepiece in /home/lahad/.local/lib/python3.10/site-packages (from torchtext==0.6) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /home/lahad/.local/lib/python3.10/site-packages (from torchtext==0.6) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Requirement already satisfied: requests in /home/lahad/.local/lib/python3.10/site-packages (from torchtext==0.6) (2.31.0)\n",
            "Requirement already satisfied: numpy in /home/lahad/.local/lib/python3.10/site-packages (from torchtext==0.6) (1.26.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchtext==0.6) (2020.6.20)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lahad/.local/lib/python3.10/site-packages (from requests->torchtext==0.6) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lahad/.local/lib/python3.10/site-packages (from requests->torchtext==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchtext==0.6) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.3.1)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (2.3.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (10.3.2.106)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->torchtext==0.6) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.0.106)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->torchtext==0.6) (1.9)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.105)\n",
            "Requirement already satisfied: fsspec in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (2023.12.2)\n",
            "Requirement already satisfied: networkx in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (12.1.105)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (4.8.0)\n",
            "Requirement already satisfied: filelock in /home/lahad/.local/lib/python3.10/site-packages (from torch->torchtext==0.6) (3.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lahad/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6) (12.3.101)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torchtext==0.6   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "JC83scb3ZN4D"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import spacy\n",
        "import stanza\n",
        "from torchtext.data import Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "QFiJAhB9Zz3A",
        "outputId": "0cb07fc4-d933-473f-df10-81dcb6ee89c6"
      },
      "outputs": [],
      "source": [
        "# # !pip install transformers datasets\n",
        "# # from datasets import load_dataset\n",
        "# from google.colab import drive\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "data = pd.read_csv(\"data/train.csv\")\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc_MZXi_iHha"
      },
      "outputs": [],
      "source": [
        "data.head()\n",
        "wolof = data[\"WOLOF\"]\n",
        "francais = data[\"FRENCH\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyaWRJe9ijc_"
      },
      "outputs": [],
      "source": [
        "wolof_sentences = [sentence.rstrip('\\n').lower() for sentence in wolof]\n",
        "francais_sentences = [sentence.rstrip('\\n') for sentence in francais]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxpTRLmzjWbg",
        "outputId": "5320b4b7-68a3-426b-d5d5-9023654c98d5"
      },
      "outputs": [],
      "source": [
        "wolof_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7zkFA3plKI_",
        "outputId": "5119dcf0-c07a-49f1-edd7-63d1862fce52"
      },
      "outputs": [],
      "source": [
        "francais_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c06d678f21644b20b2fdcdb3500e7410",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-25 18:38:32 INFO: Downloaded file to /home/lahad/stanza_resources/resources.json\n",
            "2024-04-25 18:38:32 INFO: Downloading default packages for language: wo (Wolof) ...\n",
            "2024-04-25 18:38:33 INFO: File exists: /home/lahad/stanza_resources/wo/default.zip\n",
            "2024-04-25 18:38:33 INFO: Finished downloading models and saved to /home/lahad/stanza_resources\n",
            "2024-04-25 18:38:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28636fcfdb794fbab9aa85e153a84702",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-25 18:38:33 INFO: Downloaded file to /home/lahad/stanza_resources/resources.json\n",
            "2024-04-25 18:38:33 WARNING: Language wo package default expects mwt, which has been added\n",
            "2024-04-25 18:38:33 INFO: Loading these models for language: wo (Wolof):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | wtb     |\n",
            "| mwt       | wtb     |\n",
            "=======================\n",
            "\n",
            "2024-04-25 18:38:33 INFO: Using device: cpu\n",
            "2024-04-25 18:38:33 INFO: Loading: tokenize\n",
            "2024-04-25 18:38:33 INFO: Loading: mwt\n",
            "2024-04-25 18:38:33 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "spacy_frenc = spacy.load(\"fr_core_news_sm\")\n",
        "stanza.download('wo')\n",
        "\n",
        "# Initialiser le pipeline de traitement avec tokenisation\n",
        "stanza_wolof = stanza.Pipeline(lang='wo', processors='tokenize')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Dafa', 'am', 'solo', 'motax', '.', 'ndax', 'dinga', 'dém', 'si', 'biir', '?']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize_wolof(text):\n",
        "    doc = stanza_wolof(text)\n",
        "    tokens = [token.text for sentence in doc.sentences for token in sentence.tokens]\n",
        "    return tokens\n",
        "text = \"Dafa am solo motax. ndax dinga dém si biir?\"\n",
        "# tokenize_wolof(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_french(text):\n",
        "    doc = spacy_frenc(text)\n",
        "    tokens = [token.text for token in doc]\n",
        "    return tokens\n",
        "\n",
        "text = \"Je suis une étudiante. Est-ce que tu viens avec moi?\"\n",
        "# tokenize_french(text)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "wolof = Field(tokenize=tokenize_wolof, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "french = Field(tokenize=tokenize_french, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "wolof.build_vocab(wolof_sentences, max_size=10000, min_freq=2)\n",
        "french.build_vocab(francais_sentences, max_size=10000, min_freq=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                  embedding_size, # taille de l'embedding\n",
        "                  src_vocab_size, # taille du vocabulaire source\n",
        "                  trg_vocab_size, # taille du vocabulaire cible\n",
        "                  src_pad_idx, # index du token de padding\n",
        "                  num_heads, # nombre de têtes d'attention\n",
        "                  num_encoder_layers, # nombre de couches de l'encodeur\n",
        "                  num_decoder_layers, # nombre de couches du décodeur\n",
        "                  forward_expansion, # expansion du feedforward\n",
        "                  dropout,   # dropout pour la régularisation de la couche de sortie\n",
        "                  max_length, # longueur maximale\n",
        "                  device # device\n",
        "                        ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size) # embedding de la source\n",
        "        self.src_position_embedding = nn.Embedding(max_length, embedding_size) # embedding de la position de la source\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size) # embedding de la cible\n",
        "        self.trg_position_embedding = nn.Embedding(max_length, embedding_size) # embedding de la position de la cible\n",
        "        self.device = device # device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size) # couche de sortie\n",
        "        self.dropout = nn.Dropout(dropout) # dropout pour la régularisation de la couche de sortie \n",
        "        self.src_pad_idx = src_pad_idx # index du token de padding \n",
        "\n",
        "    def make_src_mask(self, src): # masque pour la source \n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx # on prend le transpose [S, N] pour avoir la forme [N, S]\n",
        "        return src_mask.to(self.device)\n",
        "    def forward(self, src, trg):\n",
        "        src_seg_len, N = src.shape # longueur de la source\n",
        "        trg_seg_len, N = trg.shape  # longueur de la cible\n",
        "\n",
        "        src_positions = ( # positions de la source \n",
        "            torch.arange(0, src_seg_len).unsqueeze(1).expand(src_seg_len, N).to(self.device)\n",
        "        )\n",
        "        trg_positions = ( # positions de la cible\n",
        "            torch.arange(0, trg_seg_len).unsqueeze(1).expand(trg_seg_len, N).to(self.device)\n",
        "        )\n",
        "        embed_src = self.dropout((self.src_word_embedding(src) + self.src_position_embedding(src_positions))) # embedding de la source\n",
        "        embed_trg = self.dropout((self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))) # embedding de la cible\n",
        "        src_padding_mask = self.make_src_mask(src) # masque pour la source \n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seg_len).to(self.device) # masque pour la cible*\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask = src_padding_mask,\n",
        "            tgt_mask = trg_mask\n",
        "        ) # transformer \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
